{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete,Box,Dict,Tuple,MultiBinary,MultiDiscrete\n",
    "\n",
    "import tensorboard\n",
    "\n",
    "#import helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#import Stable baselines stuff\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##types of spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42217064, 0.5528013 , 0.412918  ],\n",
       "       [0.576677  , 0.7211167 , 0.03239008],\n",
       "       [0.744463  , 0.959288  , 0.51784456]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1,shape=(3,3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " array([[0.15574369, 0.5806547 , 0.92971927],\n",
       "        [0.41837105, 0.9400347 , 0.98770237],\n",
       "        [0.6252329 , 0.18121397, 0.6097918 ]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple((Discrete(3),Box(0,1,shape=(3,3)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('height', 1), ('speed', array([48.326447], dtype=float32))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height':Discrete(2), 'speed': Box(0,100,shape=(1,))}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5,2,2]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building an Environment\n",
    "\n",
    "#build agent to give us the best shower possible\n",
    "#Randomly temperature\n",
    "#37 and 39 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take, down, stay, up\n",
    "        self.action_space = Discrete(3)\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "        # Set start temp\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        # Set shower length\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        # 0 -1 = -1 temperature\n",
    "        # 1 -1 = 0 \n",
    "        # 2 -1 = 1 temperature \n",
    "        self.state += action -1 \n",
    "        # Reduce shower length by 1 second\n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >=37 and self.state <=39: \n",
    "            reward =1 \n",
    "        else: \n",
    "            reward = -1 \n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Apply temperature noise\n",
    "        #self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        # Reset shower time\n",
    "        self.shower_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74.25792], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-44\n",
      "Episode:2 Score:-22\n",
      "Episode:3 Score:-58\n",
      "Episode:4 Score:-8\n",
      "Episode:5 Score:-38\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "#trian model\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "log_path=os.path.join('Training','logs')\n",
    "model=PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/logs/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -32.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -35.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 914         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403063 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.000237   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -34.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1216         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090940315 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.000302     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 66.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -30.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1461        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012079691 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -3.02e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -26.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1657        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009048096 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -4.17e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -22.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1824         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010654865 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -5.16e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 0.000644     |\n",
      "|    value_loss           | 69.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -27.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1962        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010598512 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -4.47e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 78          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -27.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2074        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009883525 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.00125    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 73.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -27.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2172        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013754114 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | -5.15e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -24.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2260        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008453043 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.00171     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x106d60c70>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "\n",
    "shower_path = os.path.join('Trianing','saved models','shower_model_ppo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sampson/miniforge3/envs/tensorflow24/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'Trianing/saved models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.0, 58.787753826796276)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tensorflow24')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fe0b1752bef58208e61c2c54ac686efbfd88b3c1c73b7f80dc2982421c99342"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
